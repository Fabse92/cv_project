%!TEX root = ../poster.tex

Human environments are full of significant objects - from pens, to coffee mugs, to computer monitors - which a mobile robot system might need to find, examine, manipulate or otherwise interact with.
But how can the robot identify what is an object and what is not? And, when dropped into an unknown environment, how can it intelligently explore in order to increase its knowledge of the locations and shapes of the objects in its vicinity as efficiently as possible?

This project investigated object detection and the "next best view" (NBV) problem: given the robot's current knowledge about its environment, where should it move to next in order to maximally increase its knowledge?