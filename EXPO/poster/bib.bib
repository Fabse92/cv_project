% Encoding: UTF-8
@inproceedings{garcia2013computational,
  title={{A Computational Framework for Attentional 3D Object Detection}},
  author={Garc{\'i}a, Germ{\'a}n Mart{\'i}n and Frintrop, Simone},
  booktitle={Proc. of the Annual Conf. of the Cognitive Science Society},
  year={2013}
}

@Article{monica2017,
author="Monica, Riccardo
and Aleotti, Jacopo",
title={{Contour-based next-best view planning from point cloud segmentation of unknown objects}},
journal="Autonomous Robots",
year="2017",
month="Feb",
day="06",
abstract="A novel strategy is presented to determine the next-best view for a robot arm, equipped with a depth camera in eye-in-hand configuration, which is oriented to autonomous exploration of unknown objects. Instead of maximizing the total size of the expected unknown volume that becomes visible, the next-best view is chosen to observe the border of incomplete objects. Salient regions of space that belong to the objects are detected, without any prior knowledge, by applying a point cloud segmentation algorithm. The system uses a Kinect V2 sensor, which has not been considered in previous works on next-best view planning, and it exploits KinectFusion to maintain a volumetric representation of the environment. A low-level procedure to reduce Kinect V2 invalid points is also presented. The viability of the approach has been demonstrated in a real setup where the robot is fully autonomous. Experiments indicate that the proposed method enables the robot to actively explore the objects faster than a standard next-best view algorithm.",
issn="1573-7527",
doi="10.1007/s10514-017-9618-0",
url="https://doi.org/10.1007/s10514-017-9618-0"
}

@article{surmann2003autonomous,
title = {{An autonomous mobile robot with a 3D laser range finder for 3D exploration and digitalization of indoor environments}},
journal = "Robotics and Autonomous Systems",
volume = "45",
number = "3",
pages = "181 - 198",
year = "2003",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2003.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889003001556",
author = "Hartmut Surmann and Andreas N{\"u}chter and Joachim Hertzberg",
keywords = "Autonomous mobile robots",
keywords = "3D laser range finder",
keywords = "Scan matching",
keywords = "Next best view planning",
keywords = "3D digitalization",
keywords = "3D gaging",
keywords = "Robot relocalization",
keywords = "SLAM"
}

@ARTICLE{calli2015benchmarking,
author={B. Calli and A. Walsman and A. Singh and S. Srinivasa and P. Abbeel and A. M. Dollar},
journal={IEEE Robotics Automation Magazine},
title={{Benchmarking in Manipulation Research: Using the Yale-CMU-Berkeley Object and Model Set}},
year={2015},
volume={22},
number={3},
pages={36-52},
keywords={benchmark testing;learning (artificial intelligence);planning (artificial intelligence);robots;RGB-D scans;Yale-CMU-Berkeley model set;Yale-CMU-Berkeley object set;associated database;benchmarking;geometric models;high-resolution red green blue plus depth scans;learning;manipulation tests;mechanical design;physical properties;planning software platforms;robotic manipulation research;Benchmark testing;Data models;Databases;Object detection;Prosthetics;Robots;Solid modeling},
doi={10.1109/MRA.2015.2448951},
ISSN={1070-9932},
month={Sept},}