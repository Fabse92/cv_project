% Encoding: UTF-8
@article{atanasov2014nonmyopic,
  title={Nonmyopic view planning for active object classification and pose estimation},
  author={Atanasov, Nikolay and Sankaran, Bharath and Le Ny, Jerome and Pappas, George J and Daniilidis, Kostas},
  journal={IEEE Transactions on Robotics},
  volume={30},
  number={5},
  pages={1078--1090},
  year={2014},
  publisher={IEEE}
}

@inproceedings{garcia2013computational,
  title={A computational framework for attentional 3D object detection},
  author={Garc{\'i}a, Germ{\'a}n Mart{\'i}n and Frintrop, Simone},
  booktitle={Proc. of the Annual Conf. of the Cognitive Science Society},
  year={2013},
  organization={Citeseer}
}

@inproceedings{meger2010curious,
  title={Curious george: An integrated visual search platform},
  author={Meger, David and Muja, Marius and Helmer, Scott and Gupta, Ankur and Gamroth, Catherine and Hoffman, Tomas and Baumann, Matthew and Southey, Tristram and Fazli, Pooyan and Wohlkinger, Walter and others},
  booktitle={Computer and Robot Vision (CRV), 2010 Canadian Conference on},
  pages={107--114},
  year={2010},
  organization={IEEE}
}

@INPROCEEDINGS{garcia2015saliency,
author={G. M. García and E. Potapova and T. Werner and M. Zillich and M. Vincze and S. Frintrop},
booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)},
title={{Saliency-based object discovery on RGB-D data with a late-fusion approach}},
year={2015},
volume={},
number={},
pages={1866-1873},
keywords={image colour analysis;image fusion;image segmentation;image sequences;object recognition;RGB-D data;clutter;color segmentation algorithms;depth segmentation algorithms;indoor scenes;late-fusion approach;object candidates ranking;saliency-based object discovery;segment extraction;sequence;Color;Image color analysis;Image segmentation;Proposals;Robots;Support vector machines;Three-dimensional displays},
doi={10.1109/ICRA.2015.7139441},
ISSN={1050-4729},
month={May},}

@inproceedings{papon2013voxel,
  title={Voxel cloud connectivity segmentation-supervoxels for point clouds},
  author={Papon, Jeremie and Abramov, Alexey and Schoeler, Markus and Worgotter, Florentin},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2027--2034},
  year={2013}
}

@InProceedings{frintrop2015traditional,
author = {Frintrop, Simone and Werner, Thomas and Martin Garcia, German},
title = {{Traditional Saliency Reloaded: A Good Old Model in New Shape}},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}


@Article{felzenszwalb2004efficient,
author="Felzenszwalb, Pedro F.
and Huttenlocher, Daniel P.",
title={{Efficient Graph-Based Image Segmentation}},
journal="International Journal of Computer Vision",
year="2004",
month="Sep",
day="01",
volume="59",
number="2",
pages="167--181",
abstract="This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.",
issn="1573-1405",
doi="10.1023/B:VISI.0000022288.19776.77",
url="https://doi.org/10.1023/B:VISI.0000022288.19776.77"
}

@article{surmann2003autonomous,
title = {{An autonomous mobile robot with a 3D laser range finder for 3D exploration and digitalization of indoor environments}},
journal = "Robotics and Autonomous Systems",
volume = "45",
number = "3",
pages = "181 - 198",
year = "2003",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2003.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S0921889003001556",
author = "Hartmut Surmann and Andreas Nüchter and Joachim Hertzberg",
keywords = "Autonomous mobile robots",
keywords = "3D laser range finder",
keywords = "Scan matching",
keywords = "Next best view planning",
keywords = "3D digitalization",
keywords = "3D gaging",
keywords = "Robot relocalization",
keywords = "SLAM"
}

@inproceedings{li2016incremental,
  title={Incremental scene understanding on dense SLAM},
  author={Li, Chi and Xiao, Han and Tateno, Keisuke and Tombari, Federico and Navab, Nassir and Hager, Gregory D},
  booktitle={Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on},
  pages={574--581},
  year={2016},
  organization={IEEE}
}

@article{brooks1986,
author={R. Brooks},
journal={IEEE Journal on Robotics and Automation},
title={A robust layered control system for a mobile robot},
year={1986},
volume={2},
number={1},
pages={14-23},
keywords={Hierarchical systems;Robots, locomotion;Robustness;Acoustic sensors;Boundary conditions;Control systems;Infrared sensors;Laboratories;Mobile robots;Robot control;Robot sensing systems;Robotics and automation;Robust control},
doi={10.1109/JRA.1986.1087032},
ISSN={0882-4967},
month={Mar},}

@ARTICLE{grisetti2007,
author={G. Grisetti and C. Stachniss and W. Burgard},
journal={IEEE Transactions on Robotics},
title={{Improved Techniques for Grid Mapping With Rao-Blackwellized Particle Filters}},
year={2007},
volume={23},
number={1},
pages={34-46},
keywords={SLAM (robots);mobile robots;particle filtering (numerical methods);Rao-Blackwellized particle filters;grid mapping;mobile robots;particle depletion;simultaneous localization and mapping problem;Computer science;Contracts;Distributed computing;Mobile robots;Orbital robotics;Particle filters;Proposals;Robot sensing systems;Simultaneous localization and mapping;Uncertainty;Adaptive resampling;Rao-Blackwellized particle filter (RBPF);improved proposal;motion model;simultaneous localization and mapping (SLAM)},
doi={10.1109/TRO.2006.889486},
ISSN={1552-3098},
month={Feb},}

@INPROCEEDINGS{yamauchi1997frontier,
author={B. Yamauchi},
booktitle={Computational Intelligence in Robotics and Automation, 1997. CIRA'97., Proceedings., 1997 IEEE International Symposium on Computational Intelligence},
title={{A frontier-based approach for autonomous exploration}},
year={1997},
volume={},
number={},
pages={146-151},
keywords={intelligent control;laser beam applications;mobile robots;path planning;probability;sonar;autonomous exploration;evidence grids;frontier detection;laser-limited sonar;mobile robot;navigation;office environments;path planning;probability;specular reflections;Artificial intelligence;Humans;Indoor environments;Laboratories;Mobile robots;Orbital robotics;Sonar navigation;Space exploration;Testing},
doi={10.1109/CIRA.1997.613851},
ISSN={},
month={Jul},}

@INPROCEEDINGS{newcombe2011kinectfusion,
author={R. A. Newcombe and S. Izadi and O. Hilliges and D. Molyneaux and D. Kim and A. J. Davison and P. Kohi and J. Shotton and S. Hodges and A. Fitzgibbon},
booktitle={2011 10th IEEE International Symposium on Mixed and Augmented Reality},
title={{KinectFusion: Real-time dense surface mapping and tracking}},
year={2011},
volume={},
number={},
pages={127-136},
keywords={Cameras;Image reconstruction;Iterative closest point algorithm;Real time systems;Simultaneous localization and mapping;Surface reconstruction;Three dimensional displays;AR;Dense Reconstruction;Depth Cameras;GPU;Real-Time;SLAM;Tracking;Volumetric Representation},
doi={10.1109/ISMAR.2011.6092378},
ISSN={},
month={Oct},}

@ARTICLE{hornung13octomap,
  author = {Armin Hornung and Kai M. Wurm and Maren Bennewitz and Cyrill
  Stachniss and Wolfram Burgard},
  title = {{OctoMap}: An Efficient Probabilistic {3D} Mapping Framework Based
  on Octrees},
  journal = {Autonomous Robots},
  year = 2013,
  url = {http://octomap.github.com},
  doi = {10.1007/s10514-012-9321-0},
  note = {Software available at \url{http://octomap.github.com}}
}

@ARTICLE{calli2015benchmarking,
author={B. Calli and A. Walsman and A. Singh and S. Srinivasa and P. Abbeel and A. M. Dollar},
journal={IEEE Robotics Automation Magazine},
title={{Benchmarking in Manipulation Research: Using the Yale-CMU-Berkeley Object and Model Set}},
year={2015},
volume={22},
number={3},
pages={36-52},
keywords={benchmark testing;learning (artificial intelligence);planning (artificial intelligence);robots;RGB-D scans;Yale-CMU-Berkeley model set;Yale-CMU-Berkeley object set;associated database;benchmarking;geometric models;high-resolution red green blue plus depth scans;learning;manipulation tests;mechanical design;physical properties;planning software platforms;robotic manipulation research;Benchmark testing;Data models;Databases;Object detection;Prosthetics;Robots;Solid modeling},
doi={10.1109/MRA.2015.2448951},
ISSN={1070-9932},
month={Sept},}

@Article{monica2017,
author="Monica, Riccardo
and Aleotti, Jacopo",
title={{Contour-based next-best view planning from point cloud segmentation of unknown objects}},
journal="Autonomous Robots",
year="2017",
month="Feb",
day="06",
abstract="A novel strategy is presented to determine the next-best view for a robot arm, equipped with a depth camera in eye-in-hand configuration, which is oriented to autonomous exploration of unknown objects. Instead of maximizing the total size of the expected unknown volume that becomes visible, the next-best view is chosen to observe the border of incomplete objects. Salient regions of space that belong to the objects are detected, without any prior knowledge, by applying a point cloud segmentation algorithm. The system uses a Kinect V2 sensor, which has not been considered in previous works on next-best view planning, and it exploits KinectFusion to maintain a volumetric representation of the environment. A low-level procedure to reduce Kinect V2 invalid points is also presented. The viability of the approach has been demonstrated in a real setup where the robot is fully autonomous. Experiments indicate that the proposed method enables the robot to actively explore the objects faster than a standard next-best view algorithm.",
issn="1573-7527",
doi="10.1007/s10514-017-9618-0",
url="https://doi.org/10.1007/s10514-017-9618-0"
}

@ARTICLE{endres2014rgbdslam,
author={F. Endres and J. Hess and J. Sturm and D. Cremers and W. Burgard},
journal={IEEE Transactions on Robotics},
title={{3-D Mapping With an RGB-D Camera}},
year={2014},
volume={30},
number={1},
pages={177-187},
keywords={feature extraction;image colour analysis;image motion analysis;image sensors;mobile robots;robot vision;3-D mapping;Microsoft Kinect;RGB-D camera;RGB-D sensors;detailed 3-D models;domestic robots;fast camera motions;feature descriptor;feature-poor environments;flying robots;free-hand reconstruction;online operation;open source;quadrocopters;robotics community;vacuum cleaners;validation methods;visual features;Cameras;Estimation;Robot vision systems;Simultaneous localization and mapping;Visualization;Localization;RGB-D;mapping;open source;simultaneous localization and mapping (SLAM)},
doi={10.1109/TRO.2013.2279412},
ISSN={1552-3098},
month={Feb},}

@INPROCEEDINGS{blodow2011autonomous,
author={N. Blodow and L. C. Goron and Z. C. Marton and D. Pangercic and T. Rühr and M. Tenorth and M. Beetz},
booktitle={2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
title={{Autonomous semantic mapping for robots performing everyday manipulation tasks in kitchen environments}},
year={2011},
volume={},
number={},
pages={4263-4270},
keywords={Cameras;Robots},
doi={10.1109/IROS.2011.6094665},
ISSN={2153-0858},
month={Sept},}

